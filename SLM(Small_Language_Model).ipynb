{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "block_size = 8\n",
        "batch_size = 4\n",
        "max_iters = 1000\n",
        "# eval_interval = 2500\n",
        "learning_rate = 3e-4\n",
        "eval_iters = 250\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "AqG4lcOi9w5J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "260cb045-b4d4-4686-cb39-382f5de0a6f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "print(text[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lws8C9bz76v-",
        "outputId": "d8a808b7-76a1-49f5-bc19-a4192a4ce22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Wonderful Wizard of Oz\n",
            "\n",
            "Author: L. Frank Baum\n",
            "\n",
            "Illustrator: W. W. Denslow\n",
            "\n",
            "Release Date: January 6, 2014 [EBook #43936]\n",
            "\n",
            "Language: English\n",
            "\n",
            "Character set encoding: ASCII\n",
            "\n",
            "*** START OF THIS PROJECT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(set(text))\n",
        "print(len(chars))\n",
        "vocab_size = len(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY7ES86i8c2i",
        "outputId": "946f396c-e582-46fd-f966-7cd3ba91eab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string_to_int = {ch:i for i, ch in enumerate(chars)}\n",
        "int_to_string = {i:ch for i, ch in enumerate(chars)}\n",
        "encode = lambda s: [string_to_int[c] for c in s]\n",
        "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
        "data = torch.tensor(encode(text), dtype=torch.long )\n",
        "print((data[:100]))\n",
        "decoded_data = decode(data.tolist())\n",
        "decoded_data[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "lvj_Wxss91Bi",
        "outputId": "3a7a4ab2-e6b7-43a4-f65d-2fefaf66a84a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([42, 59, 56,  1, 45, 66, 65, 55, 56, 69, 57, 72, 63,  1, 45, 60, 77, 52,\n",
            "        69, 55,  1, 66, 57,  1, 37, 77,  0,  0, 23, 72, 71, 59, 66, 69, 20,  1,\n",
            "        34, 12,  1, 28, 69, 52, 65, 62,  1, 24, 52, 72, 64,  0,  0, 31, 63, 63,\n",
            "        72, 70, 71, 69, 52, 71, 66, 69, 20,  1, 45, 12,  1, 45, 12,  1, 26, 56,\n",
            "        65, 70, 63, 66, 74,  0,  0, 40, 56, 63, 56, 52, 70, 56,  1, 26, 52, 71,\n",
            "        56, 20,  1, 32, 52, 65, 72, 52, 69, 76])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Wonderful Wizard of Oz\\n\\nAuthor: L. Frank Baum\\n\\nIllustrator: W. W. Denslow\\n\\nRelease Date: January'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get batch\n",
        "n = int(0.8 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint((len(data) - block_size), (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "x, y = get_batch('train')\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "JlSzaU1dFhp-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d81e0a1-bfb6-45a6-f3ee-9b5a1f678c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8])\n",
            "torch.Size([4, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} target is {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwQsvpkuZKTL",
        "outputId": "1652f267-6ad2-48aa-9e7f-62b892f41263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([42]) target is 59\n",
            "when input is tensor([42, 59]) target is 56\n",
            "when input is tensor([42, 59, 56]) target is 1\n",
            "when input is tensor([42, 59, 56,  1]) target is 45\n",
            "when input is tensor([42, 59, 56,  1, 45]) target is 66\n",
            "when input is tensor([42, 59, 56,  1, 45, 66]) target is 65\n",
            "when input is tensor([42, 59, 56,  1, 45, 66, 65]) target is 55\n",
            "when input is tensor([42, 59, 56,  1, 45, 66, 65, 55]) target is 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "jq4Nc2jMeX0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, index, targets=None):\n",
        "        logits = self.token_embedding_table(index)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(-1)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, index, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            logits, loss = self.forward(index)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            index_next = torch.multinomial(probs, num_samples=1)\n",
        "            index = torch.cat((index,index_next), dim=1)\n",
        "        return index\n",
        "\n",
        "model = BigramLanguageModel(vocab_size).to(device)\n",
        "m = model.to(device)\n",
        "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
        "print(generated_chars)"
      ],
      "metadata": {
        "id": "Aj41-x3zrXc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecf30897-36bc-4aff-b651-309eed034cc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "r\n",
            "?Y,OVhh'ILGiIcflQIWTHq?f'WAQ&(p,mO1SyVrYZtbhBN9UDZCQG3OIVMvNPdk!THXrY6BBQurD,qr(XWsvF6i'PfvRhM&;1FZ24yXXDh'ZWoV#N g*_hzR*1N1n-*24'AU-#FNO\n",
            "r,f'kReH,x Wgd&WQ(;FE!NduF:fFVWf'Dglr*M&-ht\n",
            "60)f]Q]owX[I\"0z\n",
            "r,M26boRQOkkeRYwnASwIaNtc9l1TbQ!LXZwXVBfXvO?L]jyBK&1trYmnnuM&KF,O6b[bu,;!LX,fOA?FoPNHafnRdWfH9KtJTMf09Wxr,.nM96rM_ gmQ[bPV*Qc\".:pnuyI-TdHjleE1:Lur_U)TD[BBaL(Rs-tDh]-gUbADNd2z4'kaz);dh-&0&6RkfS3ods;j[Ao3o4NhM&MTD\n",
            "#\"fO'FE90&kkkxFmAFWy!w'wVdDbAm;?wnz34'TDQ'vFJXv]e(AR0Y3&dkK-uuWv9Svv &NhJK1;1);ytaZ0D0Lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_iters== 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"steps:{iter} || train_loss:{losses['train']:.3f} || val_loss:{losses['val']:.3f}\")\n",
        "\n",
        "    xb , yb = get_batch('train')\n",
        "    logits, loss = model.forward(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(loss.item())\n"
      ],
      "metadata": {
        "id": "dSmurZYiymiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a819c274-1c30-404e-8ca4-6613b713dfb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "steps:0 || train_loss:4.778 || val_loss:4.771\n",
            "steps:250 || train_loss:4.711 || val_loss:4.705\n",
            "steps:500 || train_loss:4.647 || val_loss:4.618\n",
            "steps:750 || train_loss:4.572 || val_loss:4.555\n",
            "4.414540767669678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
        "print(generated_chars)"
      ],
      "metadata": {
        "id": "maGugA793NfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a560e945-c090-450a-c4bd-754706b5ec36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "24sQj!IZ\"#AFhes]HKF0&Q[rbdxyvQdqr&Iv&rsuaYS\n",
            ":U:MIPZc?mujr!tx_Ud3#Chel9P1[RQqb4D3oZPA4w;rjp0zg*M9i\"F'*Zw1tE.1X?XqP;asMeEDn2YY6BfA6bbPFLo]9UfF1I\"'CV;SCB#N3?)ub\n",
            ")TrqIeE\n",
            "rg)9(RV!aUfOmv&1SNVTVhm-9c?['I(j]9iEa;WIz#PZ&azr&D\n",
            "An[d2:L]]JefkzIB;qjX;J!jSvQu*m\"9:fRY)qV]yd&Jn*Zo UY6QswQFodkiZKke,9]xV2.Guv,\"A0xnvmvA[adk-r (x]chjX1Yp[2Fs(POS3_;Xw?E.un\n",
            "f'as_\"ygU:1)wFc.tJXwb;XKLXDXiv&21?BGsBf:1)TVb&V'C!HAwTDs;guVWAPE9vwv\n",
            "ruG-rv,4*WaSyf'E.\n",
            "v0HU9uH[90M90zQRo4PqqXe\n",
            ";WSxRsx.keoDjy.:Rm-g?G6bAPx0gUU- uG9iI!u3&(;N&(]BUo\n"
          ]
        }
      ]
    }
  ]
}